<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <title>CVPR 2020 Workshop on Adversarial Machine Learning in Computer Vision</title>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
    <link href='https://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
    <link href="css/style.css" rel="stylesheet" type="text/css"/>
</head>

<body>

<div class="container">
    <table border="00" align="center">
        <tr>
            <td width="700" align="center" valign="middle">
                <!-- <h3>NeurIPS 2022 Workshop on</h3> -->
                <br>
                <span class="title"><strong>ML4Gene&#129516;: <h3 style="display: inline;">where we stage and how to proceed</h3></strong></span></td>
        </tr>
        <tr>
        <td colspan="3" align="center"><h3>Workshop @ NeurIPS, New Orleans, US, early Dec, 2022<br><br>
<!--        <a href="https://zoom.us/j/95655960109?pwd=U3BNbVJ1M0RLYlBodjM5YThaVFlXZz09">[Zoom Meeting]</a> &nbsp &nbsp &nbsp &nbsp  &nbsp &nbsp &nbsp &nbsp  <a href="https://app.sli.do/event/0iocoe6a">[Ask & Vote Panel Questions]</a>-->
        <strong><a href="https://www.youtube.com/watch?v=FCTf5MeIBFM&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy">[Video Recording]</a> <a href="http://cvpr20.com/adversarial-machine-learning-in-computer-vision/">[NeurIPS Page]</a> [OpenReview]</strong></h3></td>
        </tr>
    </table>
    <!-- <br><p><img src="figures/schedule.png" width="1000" align="middle"></p> -->
        <!-- <p><img src="figures/main.png" width="1000" align="middle"/></p> -->
</div>

</br>

<div class="container">
    <h2>Overview</h2>
    <div class="overview">
        <p>Although computer vision models have achieved advanced performance on various recognition tasks in recent
            years, they are known to be vulnerable against adversarial examples. The existence of adversarial examples
            reveals that current computer vision models perform differently with the human vision system, and on the other
            hand provides opportunities for understanding and improving these models. </p>

        <p>In this workshop, we will focus on recent research and future directions on adversarial machine learning in
            computer vision. We aim to bring experts from the computer vision, machine learning and security communities
            together to highlight the recent progress in this area, as well as discuss the benefits of integrating
            recent progress in adversarial machine learning into general computer vision tasks. Specifically, we seek to
            study adversarial machine learning not only for enhancing the model robustness against adversarial attacks,
            but also as a guide to diagnose/explain the limitation of current computer vision models as well as
            potential improving strategies. We hope this workshop can shed light on bridging the gap between the human
            vision system and computer vision systems, and chart out cross-community collaborations, including computer
            vision, machine learning and security communities.</p>
    </div>
</div>

</br>

</br>
<div class="container">
    <h2>Awards</h2>
    <div class="schedule">
    <h3><p><strong><font color="orange"><li>DeepMind Best Paper Award</li></font></strong></p></h3>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Gupta_Improving_the_Affordability_of_Robustness_Training_for_DNNs_CVPRW_2020_paper.pdf"><papertitle>Improving the affordability of robustness training for DNNs</papertitle></a>
    <!--    <a href="https://zoom.us/wc/join/99363757774?tk=&prefer=0&track_id=&meeting_result=&jmf_code=&wpk=wcpk47981f49c6816e645b9026d8e53f7f9e&_x_zm_rtaid=INd7zUOCSNm0I3_brNOAlw.1592582626576.6da4979e147effaaa7cdeb50a3a063af&_x_zm_rhtaid=843"><strong><font color="orange">[zoom link]</font></strong></a>-->
    <br>Sidharth Gupta (University of Illinois at Urbana-Champaign); Parijat Dube (IBM Research); Ashish Verma (IBM Research)</p>

    <h3><p><strong><font color="orange"><li>DeepMind Best Extended Abstract</li></font></strong></p></h3>
    <p><a href="short_papers/14.pdf"><papertitle>On Certifying Robustness against Backdoor Attacks via Randomized Smoothing</papertitle></a>
    <!--    <a href="https://zoom.us/wc/join/93036991224?tk=&prefer=0&track_id=&meeting_result=&jmf_code=&wpk=wcpk23c93d36f9b3dc877a17d3e936cccf88&_x_zm_rtaid=INd7zUOCSNm0I3_brNOAlw.1592582626576.6da4979e147effaaa7cdeb50a3a063af&_x_zm_rhtaid=843"><strong><font color="orange">[zoom link]</font></strong></a>-->
    <br>Binghui Wang (Duke University); Xiaoyu Cao (Duke University); Jinyuan Jia (Duke University ); Neil Zhenqiang Gong (Duke University)</p>

    <h3><p><strong><font color="orange"><li>DeepMind Travel Award</li></font></strong></p></h3>
    <p>Tianfu Wu (NC State University)</p>
    <p>Nataniel Ruiz (Boston University)</p>
    <p>Jiawei Chen (Boston University)</p>
    <p>Sravanti Addepalli (Indian Institute of Science)</p>
    <p>Quentin Bouniot (CEA LIST)</p>
    <p>Jiachen Sun (University of Michigan)</p>
    <p>Kartik Gupta (Australian National University)</p>
    <p>Ligong Han (Rutgers University)</p>
    </div>
</div>

</br>

<!--<div class="container">-->
<!--    <h2>Important Dates</h2>-->
<!--    TBA-->
<!--</div>-->

<!--</br>-->

<div class="container">
    <h2>Schedule</h2>
<!--    <h3><strong>Please <a href="https://app.sli.do/event/0iocoe6a">ask and vote panel questions</a> ahead</strong></h3>-->
    <div class="schedule">
        <p><strong>08:30 - 08:40 &nbsp &nbsp &nbsp &nbsp <a href="https://www.youtube.com/watch?v=FCTf5MeIBFM&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=1">Opening Remark</a></strong></p>
        <p><strong>08:40 - 09:10 &nbsp  &nbsp &nbsp &nbsp <a href="https://www.youtube.com/watch?v=nCDJ-aRHwRc&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=2">Invited Talk 1: Alan Yuille - Defending Against Random Occluder Attacks</a></strong></p>
        <p><strong>09:10 - 09:40 &nbsp  &nbsp &nbsp &nbsp <a href="https://www.youtube.com/watch?v=iQrWtRDCQ1E&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=3">Invited Talk 2: Aleksander Madry -  What Do Our Models Learn?</a></strong></p>
        <p><strong>09:40 - 10:10 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=8mzZuyGh-ys&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=4">Invited Talk 3: Earlence Fernandes - Physical Attacks on Object Detectors</a></strong></p>
        <p><strong>10:10 - 10:40 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=I3lvCepkBS8&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=5">Invited Talk 4: Matthias Bethge - Testing Generalization</a></strong></p>
        <p><strong>10:40 - 11:10 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=AcI8dsWwUHQ&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=6">Panel Discussion I: Alan Yuille, Aleksander Madry, Earlence Fernandes and Matthias Bethge</a></strong></p>
        <p><strong>11:10 - 13:00 &nbsp &nbsp  &nbsp &nbsp Poster Session I</strong></p>
        <p><strong>13:00 - 14:00 &nbsp &nbsp  &nbsp &nbsp Lunch Break</strong></p>
        <p><strong>14:00 - 14:30 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=mhDAcpTDSiw&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=7">Invited Talk 5: Laurens van der Maaten - Adversarial Robustness: The End of the Early Years</a></strong></p>
        <p><strong>14:30 - 15:00 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=GeI0_M8DsHE&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=8">Invited Talk 6: Pin-Yu Chen - Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness</a></strong></p>
        <p><strong>15:00 - 15:30 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=lmhQWJmWfdw&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=9">Invited Talk 7: Cho-Jui Hsieh - Adversarial Robustness of Discrete Machine Learning Models</a></strong></p>
        <p><strong>15:30 - 16:00 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=Qa73AMyZ10k&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=10">Invited Talk 8: Boqing Gong - Towards Visual Recognition in the Wild: Long-Tailed Sources and Open Compound Targets</a></strong></p>
        <p><strong>16:00 - 16:30 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=vKskBYxoY84&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=11">Invited Talk 9: Thomas G. Dietterich - Setting Alarm Thresholds for Anomaly Detection</a></strong></p>
        <p><strong>16:30 - 17:00 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=TASkCAc4WbM&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=12">Panel Discussion II: Laurens van der Maaten, Pin-Yu Chen, Cho-Jui Hsieh, Boqing Gong and Thomas G. Dietterich</a></strong></p>
        <p><strong>17:00 - 18:50 &nbsp &nbsp  &nbsp &nbsp Poster Session II</strong></p>
        <p><strong>18:50 - 19:00 &nbsp &nbsp  &nbsp &nbsp Closing Remark</strong></p>
    </div>
</div>


</br>
<div class="container">
<h2>Accepted Papers</h2>
<h3><strong><font color="purple">Two Live Q&A Sessions for ALL Papers: 11:10 - 13:00 &nbsp  &  &nbsp  17:00 - 18:50 (PDT)</font></strong></h3>
<h3><strong>Please find the zoom link of each paper at <a href="http://cvpr20.com/adversarial-machine-learning-in-computer-vision/">our internal website.</a></strong></h3>
<div class="schedule">
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Agarwal_Noise_Is_Inside_Me_Generating_Adversarial_Perturbations_With_Noise_Derived_CVPRW_2020_paper.pdf"><papertitle>Noise is Inside Me! Generating Adversarial Perturbations with Noise Derived from Natural Filters</papertitle></a>
<!--    <a href="https://zoom.us/wc/join/99806558903?tk=&prefer=0&track_id=&meeting_result=&jmf_code=&wpk=wcpk14298cda60f7459d49caea99acc6d389&_x_zm_rtaid=INd7zUOCSNm0I3_brNOAlw.1592582626576.6da4979e147effaaa7cdeb50a3a063af&_x_zm_rhtaid=843"><strong><font color="orange">[zoom link]</font></strong></a>-->
    <br>Akshay Agarwal (IIIT Delhi); Mayank Vatsa (IIT Jodhpur); Richa Singh (IIIT-Delhi); Nalini Ratha (IBM)</p>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Zhang_Learning_Ordered_Top-k_Adversarial_Attacks_via_Adversarial_Distillation_CVPRW_2020_paper.pdf"><papertitle>Learning Ordered Top-k Adversarial Attacks via Adversarial Distillation</papertitle></a>
<!--    <a href="https://zoom.us/wc/join/94660657763?tk=&prefer=0&track_id=&meeting_result=&jmf_code=&wpk=wcpk2d5d6842dcf8876dd4c664d78552a01c&_x_zm_rtaid=zw3_UUlmRImfne4rQ0cn7Q.1592584197364.e3841690d6ee8b404edfd062664e5bcd&_x_zm_rhtaid=445"><strong><font color="orange">[zoom link]</font></strong></a>-->
    <br>Tianfu Wu (NC State University); Zekun Zhang (NC state university)</p>
</div>
</div>

<!--</br>-->
<!--<div class="container">-->
<!--    <h2>Call For Papers</h2>-->
<!--    <div class="call4papers">-->
<!--<!--        <p><font color="red">We recently received many inquiries about the ddl extension for the paper submission, due to the inconvenience brought by the breakout of COVID-19. We understand this hard situation for all researchers, and decide to allow 1 more week for the paper submission. This deadline is firm and will not be extended futher. If you need any other accommodations, please let us know and we will try our best to help.</font></p>-->-->
<!--        <p><strong>Submission deadline</strong>: March 15 (<strong><font color="red">NEW: March 22</font></strong>), 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Notification sent to authors</strong>: April 3, 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Camera ready deadline</strong>: April 10, 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Notification sent to authors</strong>: April 10, 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Camera ready deadline</strong>: April 17, 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Submission server</strong>: <a href="https://cmt3.research.microsoft.com/CVPRamlcv2020">https://cmt3.research.microsoft.com/CVPRamlcv2020</a></p>-->
<!--        <p><strong>Submission format</strong>: Submissions need to be <strong>anonymized</strong>, and follow the <a href="http://cvpr2020.thecvf.com/submission/main-conference/author-guidelines">CVPR 2020 Submission Guidelines</a>. The workshop considers two types of submissions: (1) <font color="orange"><strong>Long Paper</strong></font>: the page limitation is eight excluding references, and will be included in the official CVPR proceedings; (2) <font color="orange"><strong>Extended Abstract</strong></font>: the page limitation is four excluding references, and will <strong>NOT</strong> be included in the official CVPR proceedings. Based on the PC’s recommendation, the accepted long paper/extended abstract will be allocated either a contributed talk or a poster presentation.</p>-->
<!--        -->
<!--        <p>We invite submissions on <strong>any aspect of adversarial machine learning in computer vision</strong>. This includes, but is not limited to:</p>-->
<!--        <ul>-->
<!--            <li>Adversarial attacks on computer vision models in the digital/physical world</li>-->
<!--            <li>Improving model robustness against adversarial attacks</li>-->
<!--            <li>Theoretical understanding of adversarial machine learning</li>-->
<!--            <li>Applying adversarial machine learning to diagnosing/explaining computer vision models</li>-->
<!--            <li>Improving representation learning via adversarial machine learning </li>-->
<!--            <li>Applications of adversarial machine learning in computer vision tasks (e.g., generative models, image captioning, image recognition)</li>-->
<!--        </ul>-->
<!--        -->
<!--        <p><font color="red">We are excited to announce a <strong>DeepMind Best Paper Award and travel grants</strong>. The workshop is fully sponsored by DeepMind through the University of Oxford.</font></p>-->
<!--        <ul>-->
<!--            <li>The best paper award will be selected from long papers only. The winner will receive the <strong>US$ 1,500 prize and a certificate</strong> at the workshop’s closing.</li>-->
<!--            <li>The workshop has several travel grants (US$100 ~ $200 each) for authors. The travel grants will be considered especially for those from underrepresented groups, such as women and minority ethnic groups.</li>-->
<!--        </ul>-->
<!--    </div>-->
<!--</div>-->

</br>

<div class="container">
    <h2>Speakers</h2>
    <div>
        <div class="instructor">
            <a href="http://www.cs.jhu.edu/~ayuille/index.html">
                <div class="instructorphoto"><img src="figures/alanyuille.png"></div>
                <div>Alan Yuille<br>Johns Hopkins University</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="https://people.csail.mit.edu/madry/">
                <div class="instructorphoto"><img src="figures/aleksandermadry.jpg"></div>
                <div>Aleksander Mądry<br>MIT</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="http://www.earlence.com/">
                <div class="instructorphoto"><img src="figures/earlencefernandes.jpg"></div>
                <div>Earlence Fernandes<br>UW–Madison</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="http://bethgelab.org/people/matthias/">
                <div class="instructorphoto"><img src="figures/matthiasbethge.jpg"></div>
                <div>Matthias Bethge<br>University of Tübingen</div>
            </a>
        </div>
    </div>

    <p></p>
    <div>
        <div class="instructor">
            <a href="https://lvdmaaten.github.io/">
                <div class="instructorphoto"><img src="figures/laurensvandermaaten.png"></div>
                <div>Laurens van der Maaten<br>Facebook AI Research</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="https://sites.google.com/site/pinyuchenpage">
                <div class="instructorphoto"><img src="figures/pinyuchen.jpg"></div>
                <div>Pin-Yu Chen<br>IBM</div>
            </a>
        </div>
            
        <div class="instructor">
            <a href="http://web.cs.ucla.edu/~chohsieh/">
                <div class="instructorphoto"><img src="figures/chojuihsieh.jpeg"></div>
                <div>Cho-Jui Hsieh<br>UCLA</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://boqinggong.info/">
                <div class="instructorphoto"><img src="figures/boqinggong.png"></div>
                <div>Boqing Gong<br>Google</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="http://web.engr.oregonstate.edu/~tgd/">
                <div class="instructorphoto"><img src="figures/thomasdietterich.jpg"></div>
                <div>Thomas G. Dietterich<br>Oregon State University</div>
            </a>
        </div>
    </div>
</div>

<!--</br>-->
<!---->
<!--<div class="container">-->
<!--    <h2>Schedule</h2>-->
<!--    TBD-->
<!--    <!--    <div class="schedule">-->-->
<!--    <!--        TBD-->-->
<!--    <!--        <p><span class="announce_date">8:40 - 9:00</span>. Opening Remarks</p>-->-->
<!--    <!--        <p><strong>Session 1: Adversarial Attacks against Computer Vision Systems</strong></p>-->-->
<!--    <!--        <p><span class="announce_date">9:00 - 9:30 </span>. Invited Talk #1: Prof. Earlence Fernandes</p>-->-->
<!--    <!--        <p><span class="announce_date">9:30 - 10:00</span>. Invited Talk #2: Dr. Boqing Gong </p>-->-->
<!--    <!--        <p><span class="announce_date">10:00 - 10:15</span>. Contributed Talk #1 </p>-->-->
<!--    <!--        <p><span class="announce_date">10:15 - 10:30</span>. Coffee Break </p>-->-->
<!--    <!--        <p><strong>Session 2: Improving Model Robustness</strong></p>-->-->
<!--    <!--        <p><span class="announce_date">9:00 - 9:30 </span>. Invited Talk #1: Prof. Earlence Fernandes</p>-->-->
<!--    <!--        <p><span class="announce_date">9:30 - 10:00</span>. Invited Talk #2: Dr. Boqing Gong </p>-->-->
<!--    <!--        <p><span class="announce_date">10:00 - 10:15</span>. Contributed Talk #1 </p>-->-->
<!--    <!--        <p><span class="announce_date">10:15 - 10:30</span>. Coffee Break </p>-->-->
<!--    <!--        <p><strong>Session 3: Understanding the Limitation of Computer Vision Models</strong></p>-->-->
<!--    <!--        <p><span class="announce_date">9:00 - 9:30 </span>. Invited Talk #1: Prof. Earlence Fernandes</p>-->-->
<!--    <!--        <p><span class="announce_date">9:30 - 10:00</span>. Invited Talk #2: Dr. Boqing Gong </p>-->-->
<!--    <!--        <p><span class="announce_date">10:00 - 10:15</span>. Contributed Talk #1 </p>-->-->
<!--    <!--        <p><span class="announce_date">10:15 - 10:30</span>. Coffee Break </p>-->-->
<!--    <!--        <p><strong>Session 4: Interpretable and Explainable Representation Learning</strong></p>-->-->
<!--    <!--        <p><span class="announce_date">9:00 - 9:30 </span>. Invited Talk #1: Prof. Earlence Fernandes</p>-->-->
<!--    <!--        <p><span class="announce_date">9:30 - 10:00</span>. Invited Talk #2: Dr. Boqing Gong </p>-->-->
<!--    <!--        <p><span class="announce_date">10:00 - 10:15</span>. Contributed Talk #1 </p>-->-->
<!--    <!--        <p><span class="announce_date">10:15 - 10:30</span>. Coffee Break </p>-->-->
<!--    <!--    </div>-->-->
<!--</div>-->

</br>

<div class="container">
    <h2>Organizing Committee</h2>
    <div>
        <div class="instructor">
            <a href="https://cihangxie.github.io/">
                <div class="instructorphoto"><img src="figures/cihangxie.jpg"></div>
                <div>Cihang Xie<br>Johns Hopkins University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://jungyhuk.github.io/">
                <div class="instructorphoto"><img src="figures/xinyunchen.jpg"></div>
                <div>Xinyun Chen<br>UC Berkeley</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://songbai.site/">
                <div class="instructorphoto"><img src="figures/songbai.png"></div>
                <div>Song Bai<br>University of Oxford</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://aisecure.github.io/">
                <div class="instructorphoto"><img src="figures/boli.jpg"></div>
                <div>Bo Li<br>UIUC</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://kaiminghe.com/">
                <div class="instructorphoto"><img src="figures/kaiminghe.jpg"></div>
                <div>Kaiming He<br>Facebook AI Research</div>
            </a>
        </div>
    </div>

    <p></p>
    <div>
        <div class="instructor">
            <a href="https://profiles.stanford.edu/fei-fei-li">
                <div class="instructorphoto"><img src="figures/feifeili.jpg"></div>
                <div>Fei-Fei Li<br>Stanford University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://www.vision.ee.ethz.ch/en/members/detail/1/#">
                <div class="instructorphoto"><img src="figures/lucvangool.jpg"></div>
                <div>Luc Van Gool<br>ETH Zurich</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://www.robots.ox.ac.uk/~phst/">
                <div class="instructorphoto"><img src="figures/philiptorr.jpg"></div>
                <div>Philip H.S. Torr<br>University of Oxford</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/song.html">
                <div class="instructorphoto"><img src="figures/dawnsong.jpg"></div>
                <div>Dawn Song<br>UC Berkeley</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://www.cs.jhu.edu/~ayuille/index.html">
                <div class="instructorphoto"><img src="figures/alanyuille.png"></div>
                <div>Alan Yuille<br>Johns Hopkins University</div>
            </a>
        </div>
    </div>
</div>
</br>

<div class="container">
    <h2>Program Committee</h2>
    <div class="pcs-row pcs">
        <div class="pcs-column">
            <ul>
                <li>Maksym Andriushchenko (EPFL)</li>
                <li>Anurag Arnab (Google)</li>
            </ul>
        </div>
        <div class="pcs-column">
            <ul>
                <li>Hamed Pirsiavash (UMBC)</li>
                <li>Omid Poursaeed (Cornell University)</li>
            </ul>
        </div>
    </div>
</div>

</br>

<div class="container">
    <h2>Sponsor</h2>
    <div><img width="350" src="figures/DeepMind_RGB_Lockup_LogoHiRes_Blue.png"></div>
</div>

</br>

<div class="containersmall">
    <p>Please contact <a href="mailto:ml4gene@gmail.com">Hanchen</a> if you have questions. The webpage template
        is by the courtesy of <a href="https://interpretablevision.github.io/">CVPR 2020 Tutorial on Interpretable
            Machine Learning for Computer Vision</a>. Thank <a href="http://yingwei.li/">Yingwei Li</a> for making this website.</p>
</div>

<!--<p align="center" class="acknowledgement">Last updated: Jan. 6, 2017</p>-->
</body>
</html>
